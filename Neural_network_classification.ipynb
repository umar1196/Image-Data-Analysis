{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHInQGnIN2YTnK5wjb0JqV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umar1196/Image-Data-Analysis/blob/main/Neural_network_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "CGp1F_WfOCo3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1YJziOJQ2Vk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the MNIST data and applying transformations**"
      ],
      "metadata": {
        "id": "lb-CKfw_OTtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define transformations\n",
        "transformations = transforms.Compose([transforms.ToTensor(),   # convert image to pytorch tensor\n",
        "                                      transforms.Normalize((0.5,), (0.5,))]) #normalize the tensor values to have the mean 0.5 and standard deviation 0.5\n"
      ],
      "metadata": {
        "id": "MZgEzt8CTz7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the train data\n",
        "train_data = datasets.MNIST(root='/data', train=True, download=True, transform=transformations)\n",
        "train_data\n",
        "\n",
        "# loading the test data\n",
        "test_data = datasets.MNIST(root='/data', train=False, download=True, transform=transformations)"
      ],
      "metadata": {
        "id": "BDE03n5cRen-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad9b747-af74-4d66-c6c3-0e27f6328c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 106976061.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/MNIST/raw/train-images-idx3-ubyte.gz to /data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 69339263.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/MNIST/raw/train-labels-idx1-ubyte.gz to /data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 30462187.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/MNIST/raw/t10k-images-idx3-ubyte.gz to /data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4570664.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the dataloader for batching and shuffling\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "h1qLeo0sUtl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the Neural network Architecture**"
      ],
      "metadata": {
        "id": "KYCUhe8FOcLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)  # first fully connected layer with 784 input features and 128 output features\n",
        "        self.fc2 = nn.Linear(128, 64)     # second fully connected layer with 128 input features and 64 output features\n",
        "        self.fc3 = nn.Linear(64, 10)       # third fully connected layer with 64 input features and 10 output features\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)  # flatten the input image to 1D tensor\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "SMbOpfpnZEDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initializing the model, loss function and optimizer**"
      ],
      "metadata": {
        "id": "Fdh_OkPOPgrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN() # model initialization\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # select adama as optimizer\n",
        "loss_function = nn.CrossEntropyLoss() # loss function cross entropy loss"
      ],
      "metadata": {
        "id": "Nhm8ofj7aLdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model training** bold text"
      ],
      "metadata": {
        "id": "Bn2wUOczPwtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoches = 5\n",
        "\n",
        "for epoch in range(epoches):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    t=0\n",
        "    for i, (data, label) in enumerate(train_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(data)  # forward pass\n",
        "        loss = loss_function(output, label)\n",
        "\n",
        "        loss += loss.item()\n",
        "        _,pred = torch.max(output.data, 1) # obtaining predictions\n",
        "        acc += torch.sum(pred == label)\n",
        "        t += label.size(0)\n",
        "\n",
        "        loss.backward()  # backward pass\n",
        "        optimizer.step() # updating weights\n",
        "\n",
        "    print(f\"the loss after epoch {epoch} is {loss: .4f}\")\n",
        "    print(f\"the accuracy after epoch {epoch} is {acc/t: .4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNyTJ5VaaxtM",
        "outputId": "3566eebb-3702-4fed-a48b-443b03c00f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the loss after epoch 0 is  0.4887\n",
            "the accuracy after epoch 0 is  0.8994\n",
            "the loss after epoch 1 is  0.7346\n",
            "the accuracy after epoch 1 is  0.9515\n",
            "the loss after epoch 2 is  0.4639\n",
            "the accuracy after epoch 2 is  0.9628\n",
            "the loss after epoch 3 is  0.1568\n",
            "the accuracy after epoch 3 is  0.9697\n",
            "the loss after epoch 4 is  0.1704\n",
            "the accuracy after epoch 4 is  0.9729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model testing**"
      ],
      "metadata": {
        "id": "NIV839YKQQdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    acc = 0\n",
        "    t=0\n",
        "    for i, (data, label) in enumerate(test_loader):\n",
        "\n",
        "        output = model(data)\n",
        "        _,pred = torch.max(output.data, 1)\n",
        "        acc += torch.sum(pred == label)\n",
        "        t += label.size(0)\n",
        "\n",
        "print(f\"The accuracy on test data is {acc/t: .4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWJBqvlcbV87",
        "outputId": "9b5caf4b-0445-4e75-c812-b81af037dbf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on test data is  0.9658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3V8j0VowaeRa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}