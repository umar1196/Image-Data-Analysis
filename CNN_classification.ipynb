{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umar1196/Image-Data-Analysis/blob/main/CNN_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "CGp1F_WfOCo3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1YJziOJQ2Vk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the MNIST data and applying transformations**"
      ],
      "metadata": {
        "id": "lb-CKfw_OTtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define transformations\n",
        "transformations = transforms.Compose([transforms.ToTensor(),   # convert image to pytorch tensor\n",
        "                                      transforms.Normalize((0.5,), (0.5,))]) #normalize the tensor values to have the mean 0.5 and standard deviation 0.5\n"
      ],
      "metadata": {
        "id": "MZgEzt8CTz7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the train data\n",
        "train_data = datasets.MNIST(root='/data', train=True, download=True, transform=transformations)\n",
        "train_data\n",
        "\n",
        "# loading the test data\n",
        "test_data = datasets.MNIST(root='/data', train=False, download=True, transform=transformations)"
      ],
      "metadata": {
        "id": "BDE03n5cRen-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b4bdd2-c587-4710-a55b-74237fed292d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 114484439.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/MNIST/raw/train-images-idx3-ubyte.gz to /data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 28302732.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/MNIST/raw/train-labels-idx1-ubyte.gz to /data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 28746981.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/MNIST/raw/t10k-images-idx3-ubyte.gz to /data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5197961.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the dataloader for batching and shuffling\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "h1qLeo0sUtl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the CNN Architecture**"
      ],
      "metadata": {
        "id": "KYCUhe8FOcLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "  def __init__(self, num_classes):\n",
        "    super (CNN, self).__init__()\n",
        "\n",
        "    self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3) # first convolutional layer\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.maxpool1 = nn.MaxPool2d(2,2) # applying max pooling\n",
        "\n",
        "    self.cnn2 = nn.Conv2d(in_channels=16, out_channels=24, kernel_size=3) # second convolutional layer\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.batch_norm1 = nn.BatchNorm2d(num_features=24) # batch normalization\n",
        "    self.maxpool2 = nn.MaxPool2d(2,2) # second max pooling\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=24*5*5, out_features=128) #fully connetced layer\n",
        "    self.relu3 = nn.ReLU()\n",
        "    self.dropout = nn.Dropout2d(0.25)\n",
        "\n",
        "    self.output_layer = nn.Linear(in_features=128, out_features=10) # output layer\n",
        "\n",
        "\n",
        "  def forward(self, input_data):\n",
        "    output = self.cnn1(input_data)\n",
        "    output = self.relu1(output)\n",
        "    output = self.maxpool1(output)\n",
        "    #print(output.shape)\n",
        "\n",
        "    output = self.cnn2(output)\n",
        "    output = self.relu2(output)\n",
        "    output = self.batch_norm1(output)\n",
        "    output = self.maxpool2(output)\n",
        "    #print(output.shape)\n",
        "\n",
        "    output = output.view(-1, 24*5*5)\n",
        "    output = self.fc1(output)\n",
        "    output = self.relu3(output)\n",
        "    output = self.dropout(output)\n",
        "    output = self.output_layer(output)\n",
        "    #print(output.shape)\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "pvt2aqftR0F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initializing the model, loss function and optimizer**"
      ],
      "metadata": {
        "id": "Fdh_OkPOPgrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN(10) # model initialization\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # select adama as optimizer\n",
        "loss_function = nn.CrossEntropyLoss() # loss function cross entropy loss"
      ],
      "metadata": {
        "id": "Nhm8ofj7aLdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model training** bold text"
      ],
      "metadata": {
        "id": "Bn2wUOczPwtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoches = 5\n",
        "\n",
        "for epoch in range(epoches):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    t=0\n",
        "    for i, (data, label) in enumerate(train_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(data)  # forward pass\n",
        "        loss = loss_function(output, label)\n",
        "\n",
        "        loss += loss.item()\n",
        "        _,pred = torch.max(output.data, 1) # obtaining predictions\n",
        "        acc += torch.sum(pred == label)\n",
        "        t += label.size(0)\n",
        "\n",
        "        loss.backward()  # backward pass\n",
        "        optimizer.step() # updating weights\n",
        "\n",
        "    print(f\"the loss after epoch {epoch} is {loss: .4f}\")\n",
        "    print(f\"the accuracy after epoch {epoch} is {acc/t: .4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNyTJ5VaaxtM",
        "outputId": "661c9e5b-f96d-4e59-93b0-95a0315298d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1345: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the loss after epoch 0 is  0.1661\n",
            "the accuracy after epoch 0 is  0.9902\n",
            "the loss after epoch 1 is  0.0019\n",
            "the accuracy after epoch 1 is  0.9912\n",
            "the loss after epoch 2 is  0.0007\n",
            "the accuracy after epoch 2 is  0.9930\n",
            "the loss after epoch 3 is  0.0039\n",
            "the accuracy after epoch 3 is  0.9931\n",
            "the loss after epoch 4 is  0.0075\n",
            "the accuracy after epoch 4 is  0.9939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model testing**"
      ],
      "metadata": {
        "id": "NIV839YKQQdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    acc = 0\n",
        "    t=0\n",
        "    for i, (data, label) in enumerate(test_loader):\n",
        "\n",
        "        output = model(data)\n",
        "        _,pred = torch.max(output.data, 1)\n",
        "        acc += torch.sum(pred == label)\n",
        "        t += label.size(0)\n",
        "\n",
        "print(f\"The accuracy on test data is {acc/t: .4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWJBqvlcbV87",
        "outputId": "6bdcb6bb-a958-4aa9-ed60-6a474ef332f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on test data is  0.9924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZxKi4xBtVaoU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}